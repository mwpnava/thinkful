{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "In this assignment, you'll continue working with the house prices data. To complete this assignment, submit a link to a Jupyter notebook containing your solutions to the following tasks:\n",
    "\n",
    "* Load the **houseprices** data from Thinkful's database.\n",
    "* Reimplement your model from the previous checkpoint.\n",
    "* Try OLS, Lasso, Ridge, and ElasticNet regression using the same model specification. This time, you need to do **k-fold cross-validation** to choose the best hyperparameter values for your models. Which model is the best? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the houseprices data from Thinkful's database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from sklearn.linear_model import Lasso, Ridge,ElasticNet\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "houses_df = pd.read_sql_query('select * from houseprices',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reimplement your model from the previous checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing dummy variables\n",
    "\n",
    "houses_df = pd.concat([houses_df,pd.get_dummies(houses_df.mszoning, prefix=\"mszoning\", drop_first=True)], axis=1)\n",
    "houses_df = pd.concat([houses_df,pd.get_dummies(houses_df.street, prefix=\"street\", drop_first=True)], axis=1)\n",
    "\n",
    "dummy_column_names = list(pd.get_dummies(houses_df.mszoning, prefix=\"mszoning\", drop_first=True).columns)\n",
    "dummy_column_names = dummy_column_names + list(pd.get_dummies(houses_df.street, prefix=\"street\", drop_first=True).columns)\n",
    "\n",
    "#Creating a interaction feature with two or more related variables\n",
    "\n",
    "houses_df['totalsf'] = houses_df['totalbsmtsf'] + houses_df['firstflrsf'] + houses_df['secondflrsf']\n",
    "houses_df['int_over_sf'] = houses_df['totalsf'] * houses_df['overallqual']\n",
    "\n",
    "#Creating feature set for X\n",
    "X = houses_df[['overallqual', 'grlivarea', 'garagecars', 'garagearea', 'totalsf', 'int_over_sf'] + dummy_column_names]\n",
    "\n",
    "# Y is the target variable\n",
    "Y = houses_df['saleprice']\n",
    "\n",
    "\n",
    "# We need to manually add a constant\n",
    "# in statsmodels' sm\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "#Creating train and set data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.3, random_state=101)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try OLS, Lasso, Ridge, and ElasticNet regression using the same model specification. This time, you need to do k-fold cross-validation to choose the best hyperparameter values for your models. Which model is the best? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model in the training set is: 0.8260989854797562\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in the test set is: 0.633088045709367\n",
      "Mean absolute error of the prediction is: 22212.677425688515\n",
      "Mean squared error of the prediction is: 2440747178.984056\n",
      "Root mean squared error of the prediction is: 49403.91866020403\n",
      "Mean absolute percentage error of the prediction is: 12.995030707204586\n",
      "Accuracy: 0.803 (+/- 0.199)\n"
     ]
    }
   ],
   "source": [
    "#OLS\n",
    "\n",
    "##Question: if I use those line of code is also OLS?\n",
    "#results = sm.OLS(y_train, X_train).fit()\n",
    "#results.summary()\n",
    "\n",
    "lrm = LinearRegression()\n",
    "lrm.fit(X_train, y_train)\n",
    "\n",
    "y_preds_train = lrm.predict(X_train)\n",
    "y_preds_test = lrm.predict(X_test)\n",
    "\n",
    "#do k-fold cross-validation\n",
    "accuracy=cross_val_score(lrm, X_train, y_train, cv=5)\n",
    "\n",
    "print(\"R-squared of the model in the training set is: {}\".format(lrm.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in the test set is: {}\".format(lrm.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (accuracy.mean(), v.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model on the training set is: 0.8142978406288434\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.6151222223278816\n",
      "Mean absolute error of the prediction is: 23081.396021862798\n",
      "Mean squared error of the prediction is: 2560258228.498001\n",
      "Root mean squared error of the prediction is: 50598.9943427535\n",
      "Mean absolute percentage error of the prediction is: 13.678965549611696\n",
      "Accuracy: 0.796 (+/- 0.199)\n"
     ]
    }
   ],
   "source": [
    "#Lasso \n",
    "\n",
    "#My solution\n",
    "#lassoregr = Lasso(alpha=10**20.5) \n",
    "\n",
    "#Solution from thinkful\n",
    "alphas = [np.power(10.0,p) for p in np.arange(-10,40,1)]\n",
    "lassoregr = LassoCV(alphas=alphas, cv=5)\n",
    "\n",
    "lassoregr.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = lassoregr.predict(X_train)\n",
    "y_preds_test = lassoregr.predict(X_test)\n",
    "\n",
    "#do k-fold cross-validation\n",
    "accuracy=cross_val_score(lassoregr, X_train, y_train, cv=5)\n",
    "\n",
    "print(\"R-squared of the model on the training set is: {}\".format(lassoregr.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(lassoregr.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (accuracy.mean(), v.std() * 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model on the training set is: 0.8172218955900827\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.6228895607275104\n",
      "Mean absolute error of the prediction is: 22823.418049921336\n",
      "Mean squared error of the prediction is: 2508588859.1427264\n",
      "Root mean squared error of the prediction is: 50085.81494937191\n",
      "Mean absolute percentage error of the prediction is: 13.509130264741643\n",
      "Accuracy: 0.796 (+/- 0.199)\n"
     ]
    }
   ],
   "source": [
    "#Ridge\n",
    "\n",
    "# Fitting a ridge regression model. Alpha is the regularization\n",
    "# parameter (usually called lambda). As alpha gets larger, parameter\n",
    "# shrinkage grows more pronounced.\n",
    "\n",
    "\n",
    "#My solution:\n",
    "#ridgeregr = Ridge(alpha=10**20.5) \n",
    "\n",
    "\n",
    "ridgeregr=RidgeCV(alphas=alphas, cv=5)\n",
    "ridgeregr.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = ridgeregr.predict(X_train)\n",
    "y_preds_test = ridgeregr.predict(X_test)\n",
    "\n",
    "\n",
    "#do k-fold cross-validation\n",
    "accuracy=cross_val_score(ridgeregr, X_train, y_train, cv=5)\n",
    "\n",
    "print(\"R-squared of the model on the training set is: {}\".format(ridgeregr.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(ridgeregr.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (accuracy.mean(), v.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model on the training set is: 0.8188416451780465\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.6257188892730867\n",
      "Mean absolute error of the prediction is: 22672.868765219457\n",
      "Mean squared error of the prediction is: 2489767788.8960905\n",
      "Root mean squared error of the prediction is: 49897.572976008465\n",
      "Mean absolute percentage error of the prediction is: 13.408486877384773\n",
      "Accuracy: 0.795 (+/- 0.199)\n"
     ]
    }
   ],
   "source": [
    "#ElasticNet\n",
    "\n",
    "#My solution\n",
    "#elasticregr = ElasticNet(alpha=10**20.5, l1_ratio=0.5) \n",
    "\n",
    "elasticregr = ElasticNetCV(alphas=alphas, cv=5)\n",
    "elasticregr.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = elasticregr.predict(X_train)\n",
    "y_preds_test = elasticregr.predict(X_test)\n",
    "\n",
    "#do k-fold cross-validation\n",
    "accuracy=cross_val_score(elasticregr, X_train, y_train, cv=5)\n",
    "\n",
    "print(\"R-squared of the model on the training set is: {}\".format(elasticregr.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(elasticregr.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (accuracy.mean(), v.std() * 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "\n",
    "Based on numbers above, OLS model is the best one with thde highest score on R-squared of the model and accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________\n",
    "\n",
    "By: Wendy Navarrete\n",
    "\n",
    "8.15.2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
